{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas numpy matplotlib seaborn autogluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "from autogluon.timeseries import TimeSeriesDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_loader\n",
    "df = data_loader.load_data(\"washington\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get basic information about the DataFrame\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check wether all the \"Date et heure de comptage\" are every 1 hour\n",
    "print(\"Checking if all the 'Date et heure de comptage' are every 1 hour\")\n",
    "# Generate a complete range of hourly timestamps between the min and max dates in the column\n",
    "full_range = pd.date_range(start=df['Date et heure de comptage'].min(), \n",
    "                           end=df['Date et heure de comptage'].max(), \n",
    "                           freq='h')\n",
    "\n",
    "# Find missing timestamps\n",
    "missing_dates = full_range.difference(df['Date et heure de comptage'])\n",
    "\n",
    "# Print results\n",
    "if missing_dates.empty:\n",
    "    print(\"No missing dates!\")\n",
    "else:\n",
    "    print(f\"Missing dates ({len(missing_dates)}):\")\n",
    "    print(missing_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'df' is your original DataFrame with the datetime column 'Date et heure de comptage'\n",
    "\n",
    "# Step 1: Create a complete range of hourly timestamps\n",
    "full_range = pd.date_range(start=df['Date et heure de comptage'].min(), \n",
    "                           end=df['Date et heure de comptage'].max(), \n",
    "                           freq='h')\n",
    "\n",
    "# Step 2: Create a DataFrame with the full range and mark present/missing timestamps\n",
    "full_df = pd.DataFrame({'Date et heure de comptage': full_range})\n",
    "full_df['Data Present'] = full_df['Date et heure de comptage'].isin(df['Date et heure de comptage']).astype(int)\n",
    "\n",
    "# Set the datetime column as the index for plotting\n",
    "full_df.set_index('Date et heure de comptage', inplace=True)\n",
    "\n",
    "# Step 3: Plot the data availability over time\n",
    "plt.figure(figsize=(15, 5))\n",
    "full_df['Data Present'].plot(drawstyle='steps-post', color='blue')\n",
    "plt.xlabel('Date and Time')\n",
    "plt.ylabel('Data Present (1) or Missing (0)')\n",
    "plt.title('Data Availability Over Time')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create a full hourly datetime range\n",
    "full_range = pd.date_range(start=df['Date et heure de comptage'].min(), \n",
    "                           end=df['Date et heure de comptage'].max(), \n",
    "                           freq='h')\n",
    "\n",
    "# Step 2: Reindex the DataFrame\n",
    "df = df.set_index('Date et heure de comptage')\n",
    "df = df.reindex(full_range)\n",
    "\n",
    "# Step 3: Rename the index to match the original column name\n",
    "df.index.name = 'Date et heure de comptage'\n",
    "\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "# Step 4: Handle missing values (optional)\n",
    "# Option 1: Leave NaNs (explicitly missing data)\n",
    "# Option 2: Fill with a placeholder (e.g., 0)\n",
    "# df_reindexed.fillna(0, inplace=False)  # Or specify a method like \"ffill\" or \"bfill\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in each column\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract datetime features from 'Date et heure de comptage'\n",
    "df['Year'] = df['Date et heure de comptage'].dt.year\n",
    "df['Month'] = df['Date et heure de comptage'].dt.month\n",
    "df['Day'] = df['Date et heure de comptage'].dt.day\n",
    "df['Hour'] = df['Date et heure de comptage'].dt.hour\n",
    "df['DayOfWeek'] = df['Date et heure de comptage'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display statistical summaries of numerical columns\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the distribution of 'Débit horaire'\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['Débit horaire'], kde=True, bins=30)\n",
    "plt.title('Distribution of Débit horaire')\n",
    "plt.xlabel('Débit horaire')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the distribution of 'Taux d\\'occupation'\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['Taux d\\'occupation'], kde=True, bins=30)\n",
    "plt.title('Distribution of Taux d\\'occupation')\n",
    "plt.xlabel('Taux d\\'occupation')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix of numerical features\n",
    "corr_matrix = df.corr(numeric_only=True)\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize 'Débit horaire' over different hours of the day\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=df, x='Hour', y='Débit horaire', estimator='mean')\n",
    "plt.title('Average Débit horaire by Hour')\n",
    "plt.xlabel('Hour of the Day')\n",
    "plt.ylabel('Average Débit horaire')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize 'Taux d\\'occupation' over different hours of the day\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=df, x='Hour', y='Taux d\\'occupation', estimator='mean')\n",
    "plt.title('Average Taux d\\'occupation by Hour')\n",
    "plt.xlabel('Hour of the Day')\n",
    "plt.ylabel('Average Taux d\\'occupation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze 'Débit horaire' by 'Etat trafic'\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=df, x='Etat trafic', y='Débit horaire')\n",
    "plt.title('Average Débit horaire by Etat trafic')\n",
    "plt.xlabel('Etat trafic')\n",
    "plt.ylabel('Average Débit horaire')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze 'Taux d\\'occupation' by 'Etat trafic'\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=df, x='Etat trafic', y='Taux d\\'occupation')\n",
    "plt.title('Average Taux d\\'occupation by Etat trafic')\n",
    "plt.xlabel('Etat trafic')\n",
    "plt.ylabel('Average Taux d\\'occupation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Chronos with Autogluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TimeSeriesDataFrame\n",
    "# df[\"timestamp\"] = df[\"Date et heure de comptage\"]\n",
    "# df.set_index('Date et heure de comptage', inplace=True)\n",
    "\n",
    "# Add the required 'item_id' column (since this is a single time series, we use a constant ID)\n",
    "df['item_id'] = 'series_' + street\n",
    "\n",
    "df[\"Date et heure de comptage\"] = df[\"Date et heure de comptage\"].dt.tz_localize(None)\n",
    "# df[\"timestamp\"] = df[\"timestamp\"].dt.tz_localize(None)\n",
    "\n",
    "# Rename \"Date et heure de comptage\" to \"timestamp\"\n",
    "df.rename(columns={\"Date et heure de comptage\": \"timestamp\"}, inplace=True)\n",
    "\n",
    "# Rename \"Débit horaire\" to \"target\"\n",
    "df.rename(columns={\"Débit horaire\": \"target\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_df = TimeSeriesDataFrame.from_data_frame(\n",
    "    df,\n",
    "    id_column='item_id',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the cutoff point for the test set\n",
    "cutoff_date = df[\"timestamp\"].max() - pd.DateOffset(months=1) - pd.DateOffset(days=20)\n",
    "print(f\"Test set cutoff date: {cutoff_date}\")\n",
    "\n",
    "# Split the data\n",
    "train_data = ts_df.loc[ts_df.index.get_level_values(\"timestamp\") <= cutoff_date]\n",
    "test_data = ts_df.loc[ts_df.index.get_level_values(\"timestamp\") > cutoff_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"MPS device is available.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"MPS device is not available; using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.timeseries import TimeSeriesPredictor\n",
    "\n",
    "# Define the prediction length (e.g., 24 hours)\n",
    "prediction_length = 24 * 5\n",
    "\n",
    "# Initialize the predictor\n",
    "predictor = TimeSeriesPredictor(\n",
    "    prediction_length=prediction_length,\n",
    "    verbosity=3\n",
    ")\n",
    "                                \n",
    "\n",
    "# Train the predictor with fine-tuning\n",
    "predictor.fit(\n",
    "    train_data=train_data,\n",
    "    hyperparameters={\n",
    "        \"Chronos\": {\n",
    "            \"use_mps\": True,\n",
    "            \"model_path\": \"amazon/chronos-bolt-tiny\",\n",
    "            \"fine_tune\": True\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "predictions = predictor.predict(train_data.iloc[-100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the predictor\n",
    "performance = predictor.evaluate(test_data)\n",
    "print(performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cutoff_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure predictions and test data have the same structure\n",
    "# Assuming 'target' is the column in test_data and predictions\n",
    "\n",
    "# Plot predictions vs. actual values\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot actual values\n",
    "plt.plot(test_data.index.get_level_values('timestamp'),\n",
    "         test_data['target'],\n",
    "         label='Actual Values',\n",
    "         linestyle='-')\n",
    "\n",
    "# Plot predicted values\n",
    "plt.plot(predictions.index.get_level_values('timestamp'),\n",
    "         predictions['mean'],\n",
    "         label='Predicted Values',\n",
    "         linestyle='--')\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('Date and Time')\n",
    "plt.ylabel('Target Value')\n",
    "plt.title('Predictions vs. Actual Values')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
