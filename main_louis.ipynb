{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas numpy matplotlib seaborn autogluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "from autogluon.timeseries import TimeSeriesDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_loader\n",
    "street = \"washington\"\n",
    "df = data_loader.load_data(street)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get basic information about the DataFrame\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check wether all the \"Date et heure de comptage\" are every 1 hour\n",
    "print(\"Checking if all the 'Date et heure de comptage' are every 1 hour\")\n",
    "# Generate a complete range of hourly timestamps between the min and max dates in the column\n",
    "full_range = pd.date_range(start=df['Date et heure de comptage'].min(), \n",
    "                           end=df['Date et heure de comptage'].max(), \n",
    "                           freq='h')\n",
    "\n",
    "# Find missing timestamps\n",
    "missing_dates = full_range.difference(df['Date et heure de comptage'])\n",
    "\n",
    "# Print results\n",
    "if missing_dates.empty:\n",
    "    print(\"No missing dates!\")\n",
    "else:\n",
    "    print(f\"Missing dates ({len(missing_dates)}):\")\n",
    "    print(missing_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'df' is your original DataFrame with the datetime column 'Date et heure de comptage'\n",
    "\n",
    "# Step 1: Create a complete range of hourly timestamps\n",
    "full_range = pd.date_range(start=df['Date et heure de comptage'].min(), \n",
    "                           end=df['Date et heure de comptage'].max(), \n",
    "                           freq='h')\n",
    "\n",
    "# Step 2: Create a DataFrame with the full range and mark present/missing timestamps\n",
    "full_df = pd.DataFrame({'Date et heure de comptage': full_range})\n",
    "full_df['Data Present'] = full_df['Date et heure de comptage'].isin(df['Date et heure de comptage']).astype(int)\n",
    "\n",
    "# Set the datetime column as the index for plotting\n",
    "full_df.set_index('Date et heure de comptage', inplace=True)\n",
    "\n",
    "# Step 3: Plot the data availability over time\n",
    "plt.figure(figsize=(15, 5))\n",
    "full_df['Data Present'].plot(drawstyle='steps-post', color='blue')\n",
    "plt.xlabel('Date and Time')\n",
    "plt.ylabel('Data Present (1) or Missing (0)')\n",
    "plt.title('Data Availability Over Time')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create a full hourly datetime range\n",
    "full_range = pd.date_range(start=df['Date et heure de comptage'].min(), \n",
    "                           end=df['Date et heure de comptage'].max(), \n",
    "                           freq='h')\n",
    "\n",
    "# Step 2: Reindex the DataFrame\n",
    "df = df.set_index('Date et heure de comptage')\n",
    "df = df.reindex(full_range)\n",
    "\n",
    "# Step 3: Rename the index to match the original column name\n",
    "df.index.name = 'Date et heure de comptage'\n",
    "\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "# Step 4: Handle missing values (optional)\n",
    "# Option 1: Leave NaNs (explicitly missing data)\n",
    "# Option 2: Fill with a placeholder (e.g., 0)\n",
    "# df_reindexed.fillna(0, inplace=False)  # Or specify a method like \"ffill\" or \"bfill\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in each column\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract datetime features from 'Date et heure de comptage'\n",
    "df['Year'] = df['Date et heure de comptage'].dt.year\n",
    "df['Month'] = df['Date et heure de comptage'].dt.month\n",
    "df['Day'] = df['Date et heure de comptage'].dt.day\n",
    "df['Hour'] = df['Date et heure de comptage'].dt.hour\n",
    "df['DayOfWeek'] = df['Date et heure de comptage'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display statistical summaries of numerical columns\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the distribution of 'Débit horaire'\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['Débit horaire'], kde=True, bins=30)\n",
    "plt.title('Distribution of Débit horaire')\n",
    "plt.xlabel('Débit horaire')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the distribution of 'Taux d\\'occupation'\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['Taux d\\'occupation'], kde=True, bins=30)\n",
    "plt.title('Distribution of Taux d\\'occupation')\n",
    "plt.xlabel('Taux d\\'occupation')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix of numerical features\n",
    "corr_matrix = df.corr(numeric_only=True)\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize 'Débit horaire' over different hours of the day\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=df, x='Hour', y='Débit horaire', estimator='mean')\n",
    "plt.title('Average Débit horaire by Hour')\n",
    "plt.xlabel('Hour of the Day')\n",
    "plt.ylabel('Average Débit horaire')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize 'Taux d\\'occupation' over different hours of the day\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=df, x='Hour', y='Taux d\\'occupation', estimator='mean')\n",
    "plt.title('Average Taux d\\'occupation by Hour')\n",
    "plt.xlabel('Hour of the Day')\n",
    "plt.ylabel('Average Taux d\\'occupation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze 'Débit horaire' by 'Etat trafic'\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=df, x='Etat trafic', y='Débit horaire')\n",
    "plt.title('Average Débit horaire by Etat trafic')\n",
    "plt.xlabel('Etat trafic')\n",
    "plt.ylabel('Average Débit horaire')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze 'Taux d\\'occupation' by 'Etat trafic'\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=df, x='Etat trafic', y='Taux d\\'occupation')\n",
    "plt.title('Average Taux d\\'occupation by Etat trafic')\n",
    "plt.xlabel('Etat trafic')\n",
    "plt.ylabel('Average Taux d\\'occupation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Chronos with Autogluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TimeSeriesDataFrame\n",
    "# df[\"timestamp\"] = df[\"Date et heure de comptage\"]\n",
    "# df.set_index('Date et heure de comptage', inplace=True)\n",
    "\n",
    "# Add the required 'item_id' column (since this is a single time series, we use a constant ID)\n",
    "df['item_id'] = 'series_' + street\n",
    "\n",
    "df[\"Date et heure de comptage\"] = df[\"Date et heure de comptage\"].dt.tz_localize(None)\n",
    "# df[\"timestamp\"] = df[\"timestamp\"].dt.tz_localize(None)\n",
    "\n",
    "# Rename \"Date et heure de comptage\" to \"timestamp\"\n",
    "df.rename(columns={\"Date et heure de comptage\": \"timestamp\"}, inplace=True)\n",
    "\n",
    "# Rename \"Débit horaire\" to \"target\"\n",
    "df.rename(columns={\"Débit horaire\": \"target\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_df = TimeSeriesDataFrame.from_data_frame(\n",
    "    df,\n",
    "    id_column='item_id',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Define start and end times as pd.Timestamp\n",
    "start_date = pd.Timestamp(\"2024-07-01\")\n",
    "end_date = pd.Timestamp(\"2024-11-30\")\n",
    "\n",
    "# Filter data between start_date and end_date\n",
    "filtered_ts_df = ts_df.slice_by_time(start_time=start_date, end_time=end_date)\n",
    "\n",
    "# Plot the 'target' column\n",
    "for item_id in filtered_ts_df.item_ids:\n",
    "    group = filtered_ts_df.loc[item_id]\n",
    "    plt.plot(group.index, group['target'], label=f\"Item {item_id}\")\n",
    "\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Target\")\n",
    "plt.title(\"Target Time Series (July 1st to October 31st)\")\n",
    "# plt.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))  # Legend outside the plot\n",
    "plt.tight_layout()\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the cutoff point for the test set\n",
    "cutoff_date = df[\"timestamp\"].max() - pd.DateOffset(months=2)\n",
    "print(f\"Test set cutoff date: {cutoff_date}\")\n",
    "\n",
    "# Split the data\n",
    "train_data = ts_df.loc[ts_df.index.get_level_values(\"timestamp\") <= cutoff_date]\n",
    "test_data = ts_df.loc[ts_df.index.get_level_values(\"timestamp\") > cutoff_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"MPS device is available.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"MPS device is not available; using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.timeseries import TimeSeriesPredictor\n",
    "\n",
    "# Define the prediction length (e.g., 24 hours)\n",
    "prediction_length = 24 * 5\n",
    "\n",
    "# Initialize the predictor\n",
    "predictor = TimeSeriesPredictor(\n",
    "    prediction_length=prediction_length,\n",
    "    verbosity=3\n",
    ")\n",
    "                                \n",
    "\n",
    "# Train the predictor with fine-tuning\n",
    "predictor.fit(\n",
    "    train_data,\n",
    "    # presets='chronos_mini',\n",
    "    hyperparameters={\n",
    "        # \"Chronos\": {\n",
    "        #     \"use_mps\": True,\n",
    "        #     \"model_path\": \"amazon/chronos-bolt-tiny\",\n",
    "        #     \"fine_tune\": False\n",
    "        # }\n",
    "        \"Chronos\": [\n",
    "            {\"model_path\": \"amazon/chronos-bolt-mini\", \"ag_args\": {\"name_suffix\": \"ZeroShot\"}},\n",
    "            # {\"model_path\": \"amazon/chronos-bolt-tiny\", \"fine_tune\": True, \"ag_args\": {\"name_suffix\": \"FineTuned\"}},\n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "predictions = predictor.predict(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the predictor\n",
    "performance = predictor.evaluate(train_data)\n",
    "print(performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cutoff_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure predictions and test data have the same structure\n",
    "# Assuming 'target' is the column in test_data and predictions\n",
    "\n",
    "# Plot predictions vs. actual values\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot actual values\n",
    "plt.plot(test_data.index.get_level_values('timestamp'),\n",
    "         test_data['target'],\n",
    "         label='Actual Values',\n",
    "         linestyle='-')\n",
    "\n",
    "# Plot predicted values\n",
    "plt.plot(predictions.index.get_level_values('timestamp'),\n",
    "         predictions['mean'],\n",
    "         label='Predicted Values',\n",
    "         linestyle='--')\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('Date and Time')\n",
    "plt.ylabel('Target Value')\n",
    "plt.title('Predictions vs. Actual Values')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Generate predictions for the next 5 days\n",
    "predictions = predictor.predict(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Align the MultiIndex between predictions and test data\n",
    "common_index = predictions.index.intersection(test_data.index)\n",
    "\n",
    "# Extract aligned actual values and predictions\n",
    "aligned_actuals = test_data.loc[common_index, \"target\"]\n",
    "aligned_predictions = predictions.loc[common_index, \"mean\"]\n",
    "\n",
    "# Drop NaN values\n",
    "valid_mask = ~aligned_actuals.isna() & ~aligned_predictions.isna()\n",
    "aligned_actuals = aligned_actuals[valid_mask]\n",
    "aligned_predictions = aligned_predictions[valid_mask]\n",
    "\n",
    "# Ensure indices are aligned for plotting\n",
    "aligned_actuals = aligned_actuals.sort_index()\n",
    "aligned_predictions = aligned_predictions.sort_index()\n",
    "\n",
    "# Calculate RMSE for train_data predictions\n",
    "rmse_train = np.sqrt(mean_squared_error(aligned_actuals, aligned_predictions))\n",
    "print(f\"RMSE (Next 5 days after train): {rmse_train}\")\n",
    "\n",
    "# Evaluate RMSE with extended train_data + partial test_data\n",
    "durations = [24, 48, 72, 96]  # Example durations in hours\n",
    "rmse_list = []\n",
    "\n",
    "for duration in durations:\n",
    "    # Extend train_data with the first 'duration' hours of test_data\n",
    "    extended_train_data = pd.concat([\n",
    "        train_data,\n",
    "        test_data.iloc[:duration]\n",
    "    ])\n",
    "    \n",
    "    # Generate predictions\n",
    "    predictions_extended = predictor.predict(extended_train_data)\n",
    "    \n",
    "    # Align predictions and actual values\n",
    "    extended_common_index = predictions_extended.index.intersection(test_data.index)\n",
    "    aligned_actuals = test_data.loc[extended_common_index, \"target\"]\n",
    "    aligned_predictions = predictions_extended.loc[extended_common_index, \"mean\"]\n",
    "    \n",
    "    # Drop NaN values\n",
    "    valid_mask = ~aligned_actuals.isna() & ~aligned_predictions.isna()\n",
    "    aligned_actuals = aligned_actuals[valid_mask]\n",
    "    aligned_predictions = aligned_predictions[valid_mask]\n",
    "    \n",
    "    # Ensure indices are aligned for RMSE calculation\n",
    "    aligned_actuals = aligned_actuals.sort_index()\n",
    "    aligned_predictions = aligned_predictions.sort_index()\n",
    "    \n",
    "    # Calculate RMSE for the current duration\n",
    "    rmse = np.sqrt(mean_squared_error(aligned_actuals, aligned_predictions))\n",
    "    rmse_list.append(rmse)\n",
    "    print(f\"RMSE after adding {duration} hours of test data: {rmse}\")\n",
    "\n",
    "# Calculate average RMSE over all durations\n",
    "average_rmse = np.mean(rmse_list)\n",
    "print(f\"Average RMSE: {average_rmse}\")\n",
    "\n",
    "# Plot predictions vs actual values for train_data\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot actual values\n",
    "plt.plot(\n",
    "    aligned_actuals.index.get_level_values('timestamp'),\n",
    "    aligned_actuals.values,\n",
    "    label='Actual Values',\n",
    "    linestyle='-'\n",
    ")\n",
    "\n",
    "# Plot predicted values for train_data\n",
    "plt.plot(\n",
    "    aligned_predictions.index.get_level_values('timestamp'),\n",
    "    aligned_predictions.values,\n",
    "    label='Predicted Values (Train Data)',\n",
    "    linestyle='--'\n",
    ")\n",
    "\n",
    "# Optionally, add extended train_data predictions to the plot\n",
    "for duration in durations:\n",
    "    extended_train_data = pd.concat([train_data, test_data.iloc[:duration]])\n",
    "    predictions_extended = predictor.predict(extended_train_data)\n",
    "    extended_common_index = predictions_extended.index.intersection(test_data.index)\n",
    "    aligned_predictions = predictions_extended.loc[extended_common_index, \"mean\"]\n",
    "    \n",
    "    # Ensure indices are aligned for plotting\n",
    "    aligned_predictions = aligned_predictions.sort_index()\n",
    "    \n",
    "    plt.plot(\n",
    "        aligned_predictions.index.get_level_values('timestamp'),\n",
    "        aligned_predictions.values,\n",
    "        linestyle=':',\n",
    "        label=f'Predicted (Train + {duration}h Test)'\n",
    "    )\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('Date and Time')\n",
    "plt.ylabel('Target Value')\n",
    "plt.title('Predictions vs. Actual Values')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
